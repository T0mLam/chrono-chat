# ChronoChat

**ChronoChat** is a conversational AI platform that enables users to chat with video content. It supports both YouTube and local uploads and uses retrieval-augmented generation (RAG) to answer questions using video transcripts, frames, and captions. Powered by local LLMs (via **Ollama**), ChronoChat streams real-time responses with full multimodal awareness, and additional support for images and PDF uploads.

> [!NOTE]
> **ChronoChat is ideal for:** </br>
> - ‚úÖ Interviews, tutorials, and educational content </br>
> - ‚ùå Not suited for animations or silent videos </br>

## ‚ú® Key Features

* üîç **Video RAG**: Uses CLIP, Whisper, and BLIP embeddings for frame, audio, and caption-based retrieval.
* üß† **LLM Planning**: Models generate reasoning chains, plan actions, and adapt to single or multi-video chats.
* üîå **Streaming Responses**: Live WebSocket chat with markdown rendering and response progress updates.
* üé• **Multi-Video Support**: Search and reason across multiple videos in a single conversation.
* üìé **Attach Files**: Supports uploading PDFs and documents for context-aware responses (extensible).

## üèÅ Getting Started

```bash
python cli.py start
```

Then go to: [http://localhost:3000](http://localhost:3000)

## üß± Architecture

```mermaid
---
config:
  look: handDrawn
  theme: neutral
---

graph TD
  subgraph "Frontend (Next.js)"
    Sidebar["üìÇ Chats & Videos"]
    UploadUI["üì¶ Upload videos"]
    ChatUI["üí¨ Chat interface"]
    APIClient["üîó REST client"]
    WSClient["üîÑ WebSocket client"]
  end

  subgraph "Backend (FastAPI & Worker)"
    API["üß≠ FastAPI server"]
    ChatRouter["üó®Ô∏è Chat router"]
    MediaRouter["üé¨ Media router"]
    VideoRAG["üß† VideoRAG engine"]
    ContextExtractor["üîç Context extractor"]
    Retriever["üì¶ ChromaDB retriever"]
    LLMClient["ü§ñ LLM client"]
    Worker["‚öôÔ∏è Ingestion worker"]
    MediaDB["üóÑÔ∏è Vector DB"]
    MediaStorage["üìÅ Video and metadata storage"]
    VideoQueue["üìÆ Processing queue"]
  end

  Sidebar --> ChatUI
  UploadUI --> APIClient
  ChatUI --> APIClient
  ChatUI --> WSClient

  APIClient <--> API
  WSClient --> ChatRouter
  ChatRouter --> VideoRAG
  VideoRAG --> ContextExtractor
  ContextExtractor --> Retriever
  Retriever --> MediaDB
  VideoRAG --> LLMClient

  ChatRouter --> WSClient
  WSClient --> ChatUI

  API --> MediaRouter
  MediaRouter --> MediaDB
  MediaRouter --> MediaStorage
  MediaRouter --> VideoQueue
  VideoQueue --> Worker
  Worker --> ContextExtractor
  Worker --> Retriever
  Worker --> MediaDB
  Worker --> MediaStorage
```

## ‚öôÔ∏è Tech Stack

| Layer      | Tools                                 |
| ---------- | ------------------------------------- |
| Frontend   | Next.js, TailwindCSS, TypeScript      |
| Backend    | FastAPI, Celery, SQLite, ChromaDB     |
| Embeddings | CLIP (frames), Whisper (audio), BLIP  |
| LLM        | Ollama (default: `qwen:0.6b`)         |
| Storage    | Local files, ChromaDB vectors, SQLite |

## üß† How It Works

1. **Ingest Video**: Extracts audio, frames, and captions from YouTube/local videos.
2. **Embed Content**: Computes multimodal embeddings and stores them in ChromaDB.
3. **Chat Interaction**: LLM receives the user query and plans an action.
4. **RAG Flow**: Relevant chunks are retrieved based on video context.
5. **Response Streaming**: Final output is streamed to the user in real time.
